{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6klIIk1FNYiR"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUTXQI79NYiV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import DataLoader\n",
        "# from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7O0xo3V3pt7",
        "outputId": "101215fe-a00d-4498-a5e4-7dd2247e2189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwDLJMa4NYiX"
      },
      "source": [
        "# Setting and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq4Dj95TSOdD",
        "outputId": "1c6ead1c-87f8-4e2a-e0c1-362360a9f52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "data_path = './'\n",
        "cifar10 =  CIFAR10(data_path, train=True, download=True, transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor(), transforms.Normalize((125.30691805, 122.95039414, 113.86538318),(62.99321928, 62.08870764, 66.70489964))]))\n",
        "# cifar10_test = CIFAR10(data_path, train=False, download=True, transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor(), transforms.Normalize((125.30691805, 122.95039414, 113.86538318),(62.99321928, 62.08870764, 66.70489964))]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C_Ic_sKV2YQ"
      },
      "outputs": [],
      "source": [
        "train_set, valset, _ = torch.utils.data.random_split(cifar10, [2700, 300, 47000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sjc5Kse-FUyK"
      },
      "outputs": [],
      "source": [
        "idx = np.array([i for i in range(len(cifar10)) if cifar10[i][1]<2])\n",
        "idxTest = np.array([i for i in range(len(cifar10_test)) if cifar10_test[i][1]<2])\n",
        "\n",
        "# Reduce Datapoints from 10k+2k  to \n",
        "# Data Train 90% and 10%\n",
        "idx = idx[0:2700]\n",
        "idxTest = idxTest[0:300]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka0eKWY4A1GO"
      },
      "outputs": [],
      "source": [
        "cifar10_trainX = np.array([cifar10[i][0] for i in idx])\n",
        "cifar10_trainY = np.array([cifar10[i][1] for i in idx])\n",
        "\n",
        "cifar10_testX = np.array([cifar10_test[i][0] for i in idxTest])\n",
        "cifar10_testY = np.array([cifar10_test[i][1] for i in idxTest])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leS8SGFkdpSD",
        "outputId": "47555573-fa63-4c96-ea51-f46557081278"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2700, 3, 224, 224)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cifar10_trainX.shape\n",
        "# cifar10_trainY.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr_tLQosNYiY"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "random_seed = 1\n",
        "learning_rate = 0.05\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "# Architecture\n",
        "num_classes = 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3HYii9ZNYiY"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK9l6lJZNYiZ"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBxHiMsnNYia"
      },
      "source": [
        "Paper: \n",
        "- “Conv (receptive field size)-(number of channels)”.\n",
        "- The convolution stride is fixed to 1 \n",
        "- The padding is 1 pixel for 3 × 3 conv\n",
        "- Max-pooling is performed over a 2 × 2 pixel window, with stride 2.\n",
        "- Not all Conv layer are followed by Max-pooling\n",
        "\n",
        "<img src=\"VGG_16.png\" width=700px>\n",
        "\n",
        "In C configuration, 1x1 conv is a way to increase the non-linearity of the decision function without affecting the receptive fields of the conv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvV22S-ENYib"
      },
      "outputs": [],
      "source": [
        "#@title VGG16\n",
        "\n",
        "class VGG16(torch.nn.Module):\n",
        "    def __init__(self, num_classes=1) -> None:\n",
        "        super(VGG16, self).__init__()\n",
        "        #Architecture  \n",
        "        self.block_1 =torch.nn.Sequential(\n",
        "            #Two conv \n",
        "            torch.nn.Conv2d(in_channels=3, \n",
        "                            out_channels=64, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=(1, 1), \n",
        "                            padding=1\n",
        "                        ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=64, \n",
        "                            out_channels=64, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=(1, 1), \n",
        "                            padding=1\n",
        "                        ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        )\n",
        "        self.block_2 =torch.nn.Sequential(\n",
        "            #Two conv \n",
        "            torch.nn.Conv2d(in_channels=64, \n",
        "                            out_channels=128, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=(1, 1), \n",
        "                            padding=1\n",
        "                        ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=128, \n",
        "                            out_channels=128, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=(1, 1), \n",
        "                            padding=1\n",
        "                        ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        )\n",
        "        self.block_3 =torch.nn.Sequential(\n",
        "            #Three conv\n",
        "            torch.nn.Conv2d(in_channels=128,\n",
        "                            out_channels=256, \n",
        "                            kernel_size=(3, 3), stride=(1, 1), \n",
        "                            padding=1\n",
        "             ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=256,\n",
        "                            out_channels=256,\n",
        "                            kernel_size=(3, 3),\n",
        "                            stride=(1, 1), \n",
        "                            padding=1\n",
        "            ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=256, \n",
        "                            out_channels=256, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=(1, 1), \n",
        "                            padding=1\n",
        "                        ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        )\n",
        "        \n",
        "        self.block_4 =torch.nn.Sequential(\n",
        "            #Three conv\n",
        "            torch.nn.Conv2d(in_channels=256, \n",
        "                            out_channels=512, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=(1, 1), \n",
        "                            padding=1\n",
        "                        ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=512, \n",
        "                            out_channels=512, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=(1, 1), \n",
        "                            padding=1\n",
        "                        ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=512, \n",
        "                            out_channels=512, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=(1, 1), \n",
        "                            padding=1\n",
        "                        ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        )\n",
        "        self.block_5 =torch.nn.Sequential(\n",
        "            #Three conv\n",
        "            torch.nn.Conv2d(in_channels=512, \n",
        "                            out_channels=512, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=(1, 1), \n",
        "                            padding=1\n",
        "                        ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=512, \n",
        "                            out_channels=512, \n",
        "                            kernel_size=(3, 3),\n",
        "                            stride=(1, 1), \n",
        "                            padding=1\n",
        "                        ),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(in_channels=512, \n",
        "                            out_channels=512, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=(1, 1), \n",
        "                            padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        )\n",
        "\n",
        "        # #VGG_16 classifier on 1000 class\n",
        "        # self.classifier = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(in_features=512, out_features=4096),\n",
        "        #     torch.nn.ReLU(),\n",
        "        #     torch.nn.Linear(in_features=4096, out_features=4096),\n",
        "        #     torch.nn.ReLU(),\n",
        "        #     torch.nn.Linear(in_features=4096, out_features=1000),\n",
        "        # )\n",
        "\n",
        "        self.classifier = torch.nn.Linear(in_features=7*7*512, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.block_3(x)\n",
        "        x = self.block_4(x)\n",
        "        x = self.block_5(x)\n",
        "        logits = self.classifier(x.view(x.size(0), -1))\n",
        "        probs = F.sigmoid(logits)\n",
        "\n",
        "        return logits, probs.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjDHU0myNYid"
      },
      "source": [
        "## AlexNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XBzJK5ONYie"
      },
      "source": [
        "AlexNet has introduced: \n",
        "- Relu as an activation function.\n",
        "- Local Response Normalization.\n",
        "- Overlapping Max-pooling (stride < kernal size).\n",
        "\n",
        "<img src=\"AlexNet.png\" width=800px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyfMeJpTNYie"
      },
      "outputs": [],
      "source": [
        "#@title alexnet\n",
        "class AlexNet(torch.nn.Module):\n",
        "    def __init__(self, num_classes=1) -> None:\n",
        "        super().__init__()\n",
        "        #Arch\n",
        "        self.conv = torch.nn.Sequential(\n",
        "            #Input image (deepFake)--> 224*224*3 \n",
        "            #Output --> (224+2*2-1)/4 +1 = 55\n",
        "            torch.nn.Conv2d(in_channels=3, \n",
        "                            out_channels=96, \n",
        "                            kernel_size=(11, 11),\n",
        "                            stride=(4, 4), \n",
        "                            padding=2\n",
        "                        ), \n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.LocalResponseNorm(2), #Local Responise Normalization \n",
        "            torch.nn.MaxPool2d(kernel_size=(3, 3), stride=2), #Overlapping pooling #27*27*96\n",
        "\n",
        "            #27+2*2 -5 +1 = 27 \n",
        "            torch.nn.Conv2d(in_channels=96, \n",
        "                            out_channels=256, \n",
        "                            kernel_size=(5, 5), \n",
        "                            stride=1, \n",
        "                            padding=2), #27*27*256\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=(3,3), stride=2), #13*13*256\n",
        "\n",
        "            #13+2*1 -3 +1 = 13\n",
        "            torch.nn.Conv2d(in_channels=256, \n",
        "                            out_channels=384, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=1, \n",
        "                            padding=1 ), #13*13*384\n",
        "            torch.nn.ReLU(),\n",
        "            \n",
        "            torch.nn.Conv2d(in_channels=384, \n",
        "                            out_channels=384, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=1, \n",
        "                            padding=1 ), #13*13*384\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            torch.nn.Conv2d(in_channels=384, \n",
        "                            out_channels=256, \n",
        "                            kernel_size=(3, 3), \n",
        "                            stride=1, \n",
        "                            padding=1 ), #13*13*384\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=(3,3), stride=2), #6*6*256\n",
        "            \n",
        "        )\n",
        "\n",
        "        # self.classifier = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(in_features=6*6*256, out_features=4096),\n",
        "        #     torch.nn.ReLU(),\n",
        "        #     torch.nn.Linear(in_features=4096, out_features=4096),\n",
        "        #     torch.nn.ReLU(),\n",
        "        #     torch.nn.Linear(in_features=4096, out_features=num_classes),\n",
        "        # )\n",
        "        \n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=6*6*256, out_features=100),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(in_features=100, out_features=num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        logits = self.classifier(x.view(x.size(0), -1))\n",
        "        probs = F.sigmoid(logits) #Sigmoid as it's binary \n",
        "\n",
        "        return logits, probs.reshape(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH4EG1J1RpI4"
      },
      "outputs": [],
      "source": [
        "def fit(train_set, model, lr):\n",
        "  batchSize = 14\n",
        "  loader = DataLoader(train_set, batch_size=batchSize, pin_memory=True)\n",
        "  adam = torch.optim.AdamW(model.parameters(), lr)\n",
        "\n",
        "  for e in range(10): # Epochs\n",
        "    for batch_ndx, sample in enumerate(loader):\n",
        "        # sample[0] = sample[0].permute(0, 2,  3,  1)\n",
        "        # print(sample[0].shape)\n",
        "\n",
        "        for i in range(len(sample[1])):\n",
        "            if sample[1][i] != 0:\n",
        "                sample[1][i] = 1\n",
        "\n",
        "        adam.zero_grad()\n",
        "        logits, probs = model(sample[0].cuda())\n",
        "        # print(probs.shape)\n",
        "        loss = F.binary_cross_entropy(probs, sample[1].cuda().float())\n",
        "        loss.backward()\n",
        "        adam.step()\n",
        "\n",
        "        \n",
        "    print(\"Epoch: \", e)        \n",
        "    print(\"Loss: \",loss.item())\n",
        "\n",
        "  # tn, fp, fn, tp = confusion_matrix(TrainY, preds).ravel()\n",
        "  # return confusion_matrix(TrainY, preds).ravel()\n",
        "\n",
        "def scores(model):\n",
        "    val_loader = DataLoader(valset, batch_size= 256)\n",
        "\n",
        "    total_preds = []\n",
        "    total_target = []\n",
        "    for batch_ndx, sample in enumerate(val_loader):\n",
        "          # sample[0] = sample[0].permute(0, 2,  3,  1)\n",
        "          # print(sample[0].shape)\n",
        "\n",
        "          for i in range(len(sample[1])):\n",
        "              if sample[1][i] != 0:\n",
        "                  sample[1][i] = 1\n",
        "\n",
        "          logits, probs = model(sample[0].cuda())\n",
        "          # print(probs.shape)\n",
        "          total_preds.extend(probs.cpu().detach().numpy().tolist())\n",
        "          total_target.extend(sample[1].cpu().detach().numpy().tolist())\n",
        "\n",
        "    total_preds=[0 if i < 0.5 else 1 for i in total_preds]\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(total_target, total_preds).ravel()\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
        "    f1_score = 2 * ((precision * recall) / (precision + recall))\n",
        "\n",
        "    print(\"Accuracy: \", acc)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"F1 Score: \", f1_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHe0ykxUN-Yr",
        "outputId": "fabf236d-e45a-44ae-e800-228f078910b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Loss:  0.32861417531967163\n",
            "Epoch:  1\n",
            "Loss:  0.3092641234397888\n",
            "Epoch:  2\n",
            "Loss:  0.2881191372871399\n",
            "Epoch:  3\n",
            "Loss:  0.2874259948730469\n",
            "Epoch:  4\n",
            "Loss:  0.28745657205581665\n",
            "Epoch:  5\n",
            "Loss:  0.2874767780303955\n",
            "Epoch:  6\n",
            "Loss:  0.2875770628452301\n",
            "Epoch:  7\n",
            "Loss:  0.28751140832901\n",
            "Epoch:  8\n",
            "Loss:  0.2875679135322571\n",
            "Epoch:  9\n",
            "Loss:  0.2875572443008423\n",
            "Epoch:  10\n",
            "Loss:  0.2875671088695526\n",
            "Epoch:  11\n",
            "Loss:  0.28759217262268066\n",
            "Epoch:  12\n",
            "Loss:  0.28761744499206543\n",
            "Epoch:  13\n",
            "Loss:  0.2887268662452698\n",
            "Epoch:  14\n",
            "Loss:  0.28766483068466187\n",
            "Epoch:  15\n",
            "Loss:  0.28764867782592773\n",
            "Epoch:  16\n",
            "Loss:  0.28769275546073914\n",
            "Epoch:  17\n",
            "Loss:  0.28775009512901306\n",
            "Epoch:  18\n",
            "Loss:  0.2877691090106964\n",
            "Epoch:  19\n",
            "Loss:  0.28780364990234375\n",
            "Epoch:  20\n",
            "Loss:  0.2878483533859253\n",
            "Epoch:  21\n",
            "Loss:  0.28784775733947754\n",
            "Epoch:  22\n",
            "Loss:  0.2879144549369812\n",
            "Epoch:  23\n",
            "Loss:  0.2879222631454468\n",
            "Epoch:  24\n",
            "Loss:  0.28798556327819824\n",
            "Epoch:  25\n",
            "Loss:  0.28798842430114746\n",
            "Epoch:  26\n",
            "Loss:  0.288066029548645\n",
            "Epoch:  27\n",
            "Loss:  0.2881086468696594\n",
            "Epoch:  28\n",
            "Loss:  0.2881539463996887\n",
            "Epoch:  29\n",
            "Loss:  0.28819623589515686\n",
            "Epoch:  30\n",
            "Loss:  0.28823143243789673\n",
            "Epoch:  31\n",
            "Loss:  0.2882770001888275\n",
            "Epoch:  32\n",
            "Loss:  0.2882920205593109\n",
            "Epoch:  33\n",
            "Loss:  0.2883802652359009\n",
            "Epoch:  34\n",
            "Loss:  0.28839778900146484\n",
            "Epoch:  35\n",
            "Loss:  0.28845083713531494\n",
            "Epoch:  36\n",
            "Loss:  0.2884960174560547\n",
            "Epoch:  37\n",
            "Loss:  0.28853315114974976\n",
            "Epoch:  38\n",
            "Loss:  0.28858643770217896\n",
            "Epoch:  39\n",
            "Loss:  0.2886309325695038\n",
            "Epoch:  40\n",
            "Loss:  0.28867125511169434\n",
            "Epoch:  41\n",
            "Loss:  0.28871995210647583\n",
            "Epoch:  42\n",
            "Loss:  0.28876322507858276\n",
            "Epoch:  43\n",
            "Loss:  0.2888372242450714\n",
            "Epoch:  44\n",
            "Loss:  0.2888394594192505\n",
            "Epoch:  45\n",
            "Loss:  0.28886327147483826\n",
            "Epoch:  46\n",
            "Loss:  0.28891614079475403\n",
            "Epoch:  47\n",
            "Loss:  0.28895866870880127\n",
            "Epoch:  48\n",
            "Loss:  0.2889982759952545\n",
            "Epoch:  49\n",
            "Loss:  0.28903648257255554\n",
            "Epoch:  50\n",
            "Loss:  0.28907400369644165\n",
            "Epoch:  51\n",
            "Loss:  0.28911030292510986\n",
            "Epoch:  52\n",
            "Loss:  0.2891473174095154\n",
            "Epoch:  53\n",
            "Loss:  0.289181649684906\n",
            "Epoch:  54\n",
            "Loss:  0.2892167568206787\n",
            "Epoch:  55\n",
            "Loss:  0.28925108909606934\n",
            "Epoch:  56\n",
            "Loss:  0.2892845869064331\n",
            "Epoch:  57\n",
            "Loss:  0.2893171012401581\n",
            "Epoch:  58\n",
            "Loss:  0.2893484830856323\n",
            "Epoch:  59\n",
            "Loss:  0.28937870264053345\n",
            "Epoch:  60\n",
            "Loss:  0.2894077003002167\n",
            "Epoch:  61\n",
            "Loss:  0.28943538665771484\n",
            "Epoch:  62\n",
            "Loss:  0.28946197032928467\n",
            "Epoch:  63\n",
            "Loss:  0.2894872725009918\n",
            "Epoch:  64\n",
            "Loss:  0.28951147198677063\n",
            "Epoch:  65\n",
            "Loss:  0.2895343601703644\n",
            "Epoch:  66\n",
            "Loss:  0.28955593705177307\n",
            "Epoch:  67\n",
            "Loss:  0.2895761728286743\n",
            "Epoch:  68\n",
            "Loss:  0.2895951271057129\n",
            "Epoch:  69\n",
            "Loss:  0.28961288928985596\n",
            "Epoch:  70\n",
            "Loss:  0.28962966799736023\n",
            "Epoch:  71\n",
            "Loss:  0.28964558243751526\n",
            "Epoch:  72\n",
            "Loss:  0.2896609306335449\n",
            "Epoch:  73\n",
            "Loss:  0.28967589139938354\n",
            "Epoch:  74\n",
            "Loss:  0.28969067335128784\n",
            "Epoch:  75\n",
            "Loss:  0.2897052764892578\n",
            "Epoch:  76\n",
            "Loss:  0.2897200584411621\n",
            "Epoch:  77\n",
            "Loss:  0.28973448276519775\n",
            "Epoch:  78\n",
            "Loss:  0.28974905610084534\n",
            "Epoch:  79\n",
            "Loss:  0.28976359963417053\n",
            "Epoch:  80\n",
            "Loss:  0.2897782027721405\n",
            "Epoch:  81\n",
            "Loss:  0.2897927165031433\n",
            "Epoch:  82\n",
            "Loss:  0.28980720043182373\n",
            "Epoch:  83\n",
            "Loss:  0.2898216247558594\n",
            "Epoch:  84\n",
            "Loss:  0.289836049079895\n",
            "Epoch:  85\n",
            "Loss:  0.28985050320625305\n",
            "Epoch:  86\n",
            "Loss:  0.2898649573326111\n",
            "Epoch:  87\n",
            "Loss:  0.28987962007522583\n",
            "Epoch:  88\n",
            "Loss:  0.2898944020271301\n",
            "Epoch:  89\n",
            "Loss:  0.2899094820022583\n",
            "Epoch:  90\n",
            "Loss:  0.28863129019737244\n",
            "Epoch:  91\n",
            "Loss:  0.28974205255508423\n",
            "Epoch:  92\n",
            "Loss:  0.2898212969303131\n",
            "Epoch:  93\n",
            "Loss:  0.28986358642578125\n",
            "Epoch:  94\n",
            "Loss:  0.289894163608551\n",
            "Epoch:  95\n",
            "Loss:  0.28991952538490295\n",
            "Epoch:  96\n",
            "Loss:  0.2899424135684967\n",
            "Epoch:  97\n",
            "Loss:  0.2899636924266815\n",
            "Epoch:  98\n",
            "Loss:  0.2899841070175171\n",
            "Epoch:  99\n",
            "Loss:  0.29000383615493774\n"
          ]
        }
      ],
      "source": [
        "model1 = AlexNet()\n",
        "fit(train_set, model1.cuda(), 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDLBQz92s_KB",
        "outputId": "2ac6fd51-d025-420e-e5ce-cedc9215a738"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9133333333333333\n",
            "Precision:  0.9133333333333333\n",
            "Recall:  1.0\n",
            "F1 Score:  0.9547038327526133\n"
          ]
        }
      ],
      "source": [
        "scores(model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfDFLHlOpB0q",
        "outputId": "f8a43bf0-6f41-418c-be53-f9eaa3aac1b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Loss:  0.3192116618156433\n",
            "Epoch:  1\n",
            "Loss:  0.29941749572753906\n",
            "Epoch:  2\n",
            "Loss:  0.2952144145965576\n",
            "Epoch:  3\n",
            "Loss:  0.29231566190719604\n",
            "Epoch:  4\n",
            "Loss:  0.29005175828933716\n",
            "Epoch:  5\n",
            "Loss:  0.2889229655265808\n",
            "Epoch:  6\n",
            "Loss:  0.2885769009590149\n",
            "Epoch:  7\n",
            "Loss:  0.28842586278915405\n",
            "Epoch:  8\n",
            "Loss:  0.2885691821575165\n",
            "Epoch:  9\n",
            "Loss:  0.2881740927696228\n"
          ]
        }
      ],
      "source": [
        "model2 = VGG16()\n",
        "fit(train_set, model2.cuda(), 0.0001)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2e3b6b0b99173f9265a096c919266c1e062fa40aa56c24545495bcfe878eb41d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
